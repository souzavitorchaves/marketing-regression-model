# -*- coding: utf-8 -*-
"""RID155811_Desafio04.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wO13uhEihpjngyWuz2vxt1XWJcAk5Mp_

# Desafio 04: Construindo um modelo de Regressão para marketing
*link do Desafio: https://dncgroupbr.notion.site/Desafio-Construindo-um-modelo-de-Regress-o-para-marketing-1ac45e3d4ee8418a9b65ba6924be6af8*



**Tarefas a serem executadas**


1.   Análise Descritiva ✅
    
    a. Uso da função describe()

2.   Análise Exploratória ✅
    
    a. Relações e padrões relevantes, correlação e distribuição

    b. Uso do heatmap

3.   Modelagem ✅

    a. Treino e teste do modelo de Regressão  

4.   Calculando Predição ✅
    
    a. Calcule o coeficiente de determinação (r^2)

5.   Resultado ✅

    a. Plotar um gráfico com as 3 regressões usadas

    b. Função para predizer resultado com base no usuário

    c. Recebendo inputs do usuário

### Importando bibliotecas e upload do .csv ⏬
"""

# importing libraries of the project
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from xgboost import XGBRegressor
from sklearn.svm import SVR
from google.colab import files

# uploading the necessary file
upload = files.upload()

"""### Análise Descritiva ⏬


*   Identificamos que não existem valores nulos e todos são do tipo Float
através da funcão "df.info()"
*   Identificamos que não existem linhas duplicadas através da função "df.duplicated()"
*   Usamos a função "describe()" para descrever os dados do Dataframe
*   Usando o "describe()" vimos que não possuímos linhas com valores zerados


"""

# creating the dataframe to use
df = pd.read_csv("MKT.csv")

df.head(50)

# Type of data and Null Values
# we don't have Null values
# all the variables are Float
print("Type of Data and Null Values:")
df.info()

# see if we have duplicated rows
# we don't have duplicated rows
duplicates = df[df.duplicated()]
print("Duplicated rows:", duplicates)

# describing the df
df.describe()

"""### Análise Exploratória ⏬


*   Previamente com o "pairplot(df)" que 'youtube' está fortemente relacionado com sales enquanto o 'newspaper' está levemente relacionado
*   Confirmamos isso com ".corr()" que nos dá o coeficiente de correlação das variáveis
*   Com o "heatmap" plotado vimos de forma mais franca e visual a relação entre as variáveis


"""

# analyzing relationship between each pair of variables
sns.pairplot(df)
plt.show()

# seing correlation of columns, how much it is related to each other
df_corr = df.corr()
df_corr

# plotting a heatmap that better shows the correlation between variables
# founded previously
sns.heatmap(df_corr, annot=True)
plt.show()

"""### Modelando ⏬


*   Dividimos em X as colunas dos canais e y as vendas do mesmo para construir nosso df de teste e predição
*   Usamos o método "train_test_split" com tamanho do dataframe de teste relativo à 20% do original e "random_state=42"
"""

# Splitiing the DF into 2 variables to create our DF for training
X = df[['youtube', 'newspaper', 'facebook']]

y = df[['sales']]
print('X shape:', X.shape)
print('y shape:', y.shape)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""### Predição ⏬


*   Testamos 3 tipos de Regressão Linear do SKLearn, *LinearRegression, SVR e XGBRegressor*
*   Seguimos o mesmo padrão para os 3, treino com o "fit()", predição com "predict()" e cálculo do R2 Score com a base prevista "r2_score()"
*   Vimos que o método de XGBoost foi o melhor e será mostrado isso na guia "Resultado"

REGRESSÃO LINEAR
"""

# training the model with .fit
regLinear = LinearRegression().fit(X_train, y_train)

# predict the results with .predict
yLinear = regLinear.predict(X_test)

# finding the r2 score
rLinear = r2_score(y_test, yLinear)

# printing the results for documentation purposes
print("R_quadrado RegLinear =",rLinear)

"""SVR"""

# training the model with .fit
regSVR = SVR().fit(X_train, y_train)

# predict the results with .predict
ySVR= regSVR.predict(X_test)

# finding the r2 score
rSVR = r2_score(y_test, ySVR)

# printing the results for documentation purposes
print("R_quadrado RegSVR = ",rSVR)

"""XGBoost"""

# training the model with .fit
regXGB = XGBRegressor().fit(X_train, y_train)

# predict the results with .predict
yXGB = regXGB.predict(X_test)

# finding the r2 score
rXGB = r2_score(y_test, yXGB)

# printing the results for documentation purposes
print("R_quadrado RegXGB = ",rXGB)

"""### Resultado ⏬

*   Plotamos os 3 resultados de Regressão em um gráfico para ilustrar o método que performou melhor
*   Criamos uma função que recebe a lista que o usuário digitou e prevê o resultado de vendas com o algoritmo XGBoost já treinado
*   Pegamos os valores dos investimentos do usuário e retornamos o valor previsto em sales

"""

# getting r2scores of all predictions models used
r2Values = [rLinear, rSVR, rXGB]

# setting the size of y as the same of the amount of models "3"
y_pos = np.arange(len(r2Values))

# List with variables names to plot in axis=1 (labels)
labels = ['rLinear', 'rSVR', 'rXGB']

# setting x as 3 (count of r2values) and height as values of r2Values
plt.bar(y_pos, r2Values)

# adding labels of variables below the bars
for i, label in enumerate(labels):
    plt.text(i, -0.05, label, ha='center')

# adding the values of R2 in each bar
for i, v in enumerate(r2Values):
    plt.text(i, v + 0.01, f"{v:.5f}", ha='center')

# title of Y axis
plt.ylabel('R² Score')

# title of how graphic
plt.title('Comparação de Modelos')
plt.show()

"""Predição do Usuário"""

# function to pass list of values input by User
# returns a print with the "sales" predicted

def predict_results(list):
  data_predict = [values_user]
  data_predict = np.array(new_data, dtype=float)
  prediction = regXGB.predict(new_data),2
  print("Valor previsto em 'Sales': {:.2f}".format(prediction[0][0]))

# getting the investment values from user
channels = ['youtube', 'facebook', 'newspaper']
values_user = []
for i in range(0, 3):
  channel_input = float(input("Informe o valor do investimento em " + channels[i] + ": "))
  values_user.append(channel_input)

predict_results(values_user)